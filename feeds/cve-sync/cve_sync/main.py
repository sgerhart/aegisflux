import os
import json
import datetime as dt
import asyncio
import aiohttp
import logging
from typing import Dict, Any, List, Optional
from nats.aio.client import Client as NATS

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# NVD API Configuration
NVD_BASE_URL = "https://services.nvd.nist.gov/rest/json/cves/2.0"
DEFAULT_PAGE_SIZE = 2000  # Maximum allowed by NVD API
MAX_RETRIES = 3
RETRY_DELAY = 5  # seconds

# Schema version for CVE documents
CVE_SCHEMA_VERSION = "1.0"

def normalize_cvss(metrics: Dict[str, Any]) -> Dict[str, Any]:
    """Normalize CVSS scores from NVD metrics."""
    cvss_data = {
        "base": {},
        "temporal": {},
        "environmental": {}
    }
    
    # Extract CVSS v2 data
    if "cvssMetricV2" in metrics:
        for metric in metrics["cvssMetricV2"]:
            cvss_v2 = metric.get("cvssData", {})
            cvss_data["base"]["v2"] = {
                "version": "2.0",
                "vector": cvss_v2.get("vectorString"),
                "score": cvss_v2.get("baseScore"),
                "severity": cvss_v2.get("baseSeverity"),
                "access_vector": cvss_v2.get("accessVector"),
                "access_complexity": cvss_v2.get("accessComplexity"),
                "authentication": cvss_v2.get("authentication"),
                "confidentiality_impact": cvss_v2.get("confidentialityImpact"),
                "integrity_impact": cvss_v2.get("integrityImpact"),
                "availability_impact": cvss_v2.get("availabilityImpact")
            }
    
    # Extract CVSS v3 data
    if "cvssMetricV30" in metrics:
        for metric in metrics["cvssMetricV30"]:
            cvss_v3 = metric.get("cvssData", {})
            cvss_data["base"]["v3"] = {
                "version": "3.0",
                "vector": cvss_v3.get("vectorString"),
                "score": cvss_v3.get("baseScore"),
                "severity": cvss_v3.get("baseSeverity"),
                "attack_vector": cvss_v3.get("attackVector"),
                "attack_complexity": cvss_v3.get("attackComplexity"),
                "privileges_required": cvss_v3.get("privilegesRequired"),
                "user_interaction": cvss_v3.get("userInteraction"),
                "scope": cvss_v3.get("scope"),
                "confidentiality_impact": cvss_v3.get("confidentialityImpact"),
                "integrity_impact": cvss_v3.get("integrityImpact"),
                "availability_impact": cvss_v3.get("availabilityImpact")
            }
    
    # Extract CVSS v3.1 data
    if "cvssMetricV31" in metrics:
        for metric in metrics["cvssMetricV31"]:
            cvss_v31 = metric.get("cvssData", {})
            cvss_data["base"]["v3.1"] = {
                "version": "3.1",
                "vector": cvss_v31.get("vectorString"),
                "score": cvss_v31.get("baseScore"),
                "severity": cvss_v31.get("baseSeverity"),
                "attack_vector": cvss_v31.get("attackVector"),
                "attack_complexity": cvss_v31.get("attackComplexity"),
                "privileges_required": cvss_v31.get("privilegesRequired"),
                "user_interaction": cvss_v31.get("userInteraction"),
                "scope": cvss_v31.get("scope"),
                "confidentiality_impact": cvss_v31.get("confidentialityImpact"),
                "integrity_impact": cvss_v31.get("integrityImpact"),
                "availability_impact": cvss_v31.get("availabilityImpact")
            }
    
    return cvss_data

def normalize_cwe(weaknesses: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """Normalize CWE (Common Weakness Enumeration) data."""
    cwe_data = []
    for weakness in weaknesses:
        for description in weakness.get("description", []):
            cwe_data.append({
                "cwe_id": description.get("value"),
                "source": description.get("source"),
                "type": description.get("type", "Primary")
            })
    return cwe_data

def normalize_affected_products(configurations: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """Normalize affected products from CVE configurations."""
    products = []
    for config in configurations:
        for node in config.get("nodes", []):
            for cpe_match in node.get("cpeMatch", []):
                if cpe_match.get("vulnerable", False):
                    cpe_name = cpe_match.get("criteria", "")
                    if cpe_name:
                        # Parse CPE 2.3 format: cpe:2.3:a:vendor:product:version:update:edition:language:sw_edition:target_sw:target_hw:other
                        parts = cpe_name.split(":")
                        if len(parts) >= 6:
                            products.append({
                                "cpe_name": cpe_name,
                                "vendor": parts[3] if len(parts) > 3 else "",
                                "product": parts[4] if len(parts) > 4 else "",
                                "version": parts[5] if len(parts) > 5 else "",
                                "vulnerable": cpe_match.get("vulnerable", False),
                                "version_start_including": cpe_match.get("versionStartIncluding"),
                                "version_end_including": cpe_match.get("versionEndIncluding"),
                                "version_start_excluding": cpe_match.get("versionStartExcluding"),
                                "version_end_excluding": cpe_match.get("versionEndExcluding")
                            })
    return products

def normalize_references(references: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """Normalize references and external links."""
    refs = []
    for ref in references:
        refs.append({
            "url": ref.get("url"),
            "source": ref.get("source"),
            "tags": ref.get("tags", [])
        })
    return refs

def normalize_nvd(nvd_json: Dict[str, Any]) -> List[Dict[str, Any]]:
    """Normalize NVD JSON data into compact CVE documents."""
    out = []
    for v in nvd_json.get("vulnerabilities", []):
        cve = v.get("cve", {})
        
        # Extract basic CVE information
        cve_id = cve.get("id")
        if not cve_id:
            continue
            
        # Normalize descriptions
        descriptions = []
        for desc in cve.get("descriptions", []):
            descriptions.append({
                "lang": desc.get("lang", "en"),
                "value": desc.get("value", ""),
                "source": desc.get("source", "nvd")
            })
        
        # Normalize CVSS scores
        cvss_data = normalize_cvss(cve.get("metrics", {}))
        
        # Normalize CWE data
        cwe_data = normalize_cwe(cve.get("weaknesses", []))
        
        # Normalize affected products
        products = normalize_affected_products(cve.get("configurations", []))
        
        # Normalize references
        references = normalize_references(cve.get("references", []))
        
        # Create compact CVE document
        cve_doc = {
            "schema_version": CVE_SCHEMA_VERSION,
            "cve_id": cve_id,
            "source": "nvd",
            "published": cve.get("published"),
            "last_modified": cve.get("lastModified"),
            "descriptions": descriptions,
            "cvss": cvss_data,
            "cwe": cwe_data,
            "affected_products": products,
            "references": references,
            "ts": dt.datetime.utcnow().isoformat() + "Z"
        }
        
        out.append(cve_doc)
    
    return out

async def fetch_nvd_page(session: aiohttp.ClientSession, start_index: int, page_size: int, api_key: Optional[str] = None) -> Dict[str, Any]:
    """Fetch a single page of CVE data from NVD API."""
    headers = {"Accept": "application/json"}
    if api_key:
        headers["apiKey"] = api_key
    
    params = {
        "startIndex": start_index,
        "resultsPerPage": page_size
    }
    
    url = f"{NVD_BASE_URL}?{aiohttp.helpers.urlencode(params)}"
    
    for attempt in range(MAX_RETRIES):
        try:
            async with session.get(url, headers=headers, timeout=aiohttp.ClientTimeout(total=30)) as response:
                if response.status == 200:
                    data = await response.json()
                    return data
                elif response.status == 403:
                    logger.warning("Rate limited by NVD API. Waiting before retry...")
                    await asyncio.sleep(RETRY_DELAY * (attempt + 1))
                elif response.status == 429:
                    logger.warning("Too many requests. Waiting before retry...")
                    await asyncio.sleep(RETRY_DELAY * (attempt + 1))
                else:
                    logger.error(f"NVD API error: {response.status} - {await response.text()}")
                    if attempt == MAX_RETRIES - 1:
                        raise Exception(f"NVD API error: {response.status}")
                    await asyncio.sleep(RETRY_DELAY)
        except asyncio.TimeoutError:
            logger.warning(f"Timeout fetching page {start_index}. Retrying...")
            if attempt == MAX_RETRIES - 1:
                raise
            await asyncio.sleep(RETRY_DELAY)
        except Exception as e:
            logger.error(f"Error fetching page {start_index}: {e}")
            if attempt == MAX_RETRIES - 1:
                raise
            await asyncio.sleep(RETRY_DELAY)
    
    raise Exception(f"Failed to fetch page {start_index} after {MAX_RETRIES} attempts")

async def fetch_all_cves(api_key: Optional[str] = None, max_pages: Optional[int] = None) -> List[Dict[str, Any]]:
    """Fetch all CVE data from NVD API with pagination."""
    all_cves = []
    start_index = 0
    page_size = DEFAULT_PAGE_SIZE
    page_count = 0
    
    async with aiohttp.ClientSession() as session:
        while True:
            if max_pages and page_count >= max_pages:
                logger.info(f"Reached maximum pages limit: {max_pages}")
                break
                
            logger.info(f"Fetching page {page_count + 1} (start_index: {start_index})")
            
            try:
                data = await fetch_nvd_page(session, start_index, page_size, api_key)
                
                vulnerabilities = data.get("vulnerabilities", [])
                if not vulnerabilities:
                    logger.info("No more vulnerabilities found. Pagination complete.")
                    break
                
                # Normalize and add to collection
                normalized_cves = normalize_nvd(data)
                all_cves.extend(normalized_cves)
                
                logger.info(f"Fetched {len(vulnerabilities)} vulnerabilities from page {page_count + 1}")
                
                # Check if we've reached the end
                total_results = data.get("totalResults", 0)
                if start_index + len(vulnerabilities) >= total_results:
                    logger.info("Reached end of available data.")
                    break
                
                start_index += page_size
                page_count += 1
                
                # Rate limiting - be respectful to NVD API
                await asyncio.sleep(1)
                
            except Exception as e:
                logger.error(f"Failed to fetch page {page_count + 1}: {e}")
                break
    
    logger.info(f"Total CVEs fetched: {len(all_cves)}")
    return all_cves

async def publish_cves_to_nats(cves: List[Dict[str, Any]], nats_url: str):
    """Publish CVE documents to NATS."""
    nc = NATS()
    try:
        await nc.connect(servers=[nats_url])
        logger.info(f"Connected to NATS at {nats_url}")
        
        published_count = 0
        for cve_doc in cves:
            try:
                message = json.dumps(cve_doc).encode()
                await nc.publish("feeds.cve.updates", message)
                published_count += 1
                logger.debug(f"Published CVE: {cve_doc.get('cve_id')}")
            except Exception as e:
                logger.error(f"Failed to publish CVE {cve_doc.get('cve_id')}: {e}")
        
        logger.info(f"Successfully published {published_count} CVEs to NATS")
        
    except Exception as e:
        logger.error(f"Failed to connect to NATS: {e}")
        raise
    finally:
        await nc.drain()

async def run():
    """Main execution function."""
    # Configuration
    nats_url = os.getenv("NATS_URL", "nats://localhost:4222")
    nvd_api_key = os.getenv("NVD_API_KEY")  # Optional API key for higher rate limits
    max_pages = int(os.getenv("NVD_MAX_PAGES", "0")) or None  # 0 means no limit
    
    logger.info("Starting CVE sync process...")
    logger.info(f"NATS URL: {nats_url}")
    logger.info(f"NVD API Key: {'Set' if nvd_api_key else 'Not set'}")
    logger.info(f"Max pages: {max_pages or 'No limit'}")
    
    try:
        # Fetch all CVEs with pagination
        cves = await fetch_all_cves(api_key=nvd_api_key, max_pages=max_pages)
        
        if not cves:
            logger.warning("No CVEs fetched. Exiting.")
            return
        
        # Publish to NATS
        await publish_cves_to_nats(cves, nats_url)
        
        logger.info("CVE sync process completed successfully")
        
    except Exception as e:
        logger.error(f"CVE sync process failed: {e}")
        raise

if __name__ == "__main__":
    asyncio.run(run())
